# README.md

# üöÄ Portfolio Fullstack Setup

This repository now includes backend + database + Angular frontend + React frontend.

I'm documenting everything here so deployment, testing, and future improvements are easier. This includes notes about version switching between different projects and environments, as well as troubleshooting steps for Windows Docker setups. 

---

## üì¶ Requirements

- [Docker](https://docs.docker.com/get-docker/) and Docker Compose installed
- Python 3.10+  
- Node.js (modern project version, switching between works)
- Git
- Optional: Virtualenv for running scripts locally (`venv/`)

---

## ‚öôÔ∏è Environment Setup

First, copy the example environment file:

```bash
cp .env.example .env
```

Then edit `.env` to set your own values:  

```env
# For Docker Compose to configure the database container
DB_USER=your_user
DB_PASSWORD=your_password
DB_NAME=portfolio_db
DB_HOST=dashboard_db

# New variables for the Oracle database
ORACLE_PASSWORD=your_oracle_password
ORACLE_XE_DB=XEPDB1 # Default database for Oracle XE or yours

# For the FastAPI backend to connect to the database
DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:5432/${DB_NAME}
SECRET_KEY=change_me
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
```

üëâ **Tip:** Keep the `.env.example` file. That way anyone who clones the repo knows exactly what to set.

---

## üê≥ Docker Commands (Cheat Sheet)

```bash
# Build and start containers
docker compose up --build -d

# List running containers
docker compose ps

# Follow logs
docker compose logs -f

# Stop and remove containers + volumes
docker compose down -v
docker system prune -a --volumes

# Enter backend container
docker compose exec dashboard_backend bash

# Enter PostgreSQL container
docker exec -it dashboard_db sh
```

---

## üîß PostgreSQL Commands

Once inside the container:

```bash
# Connect to DB
psql -U $POSTGRES_USER -d $POSTGRES_DB

# List tables
\dt

# Describe a table
\d <table_name>

# Exit psql
\q
```

Or from host (with env variables loaded):

```bash
docker compose exec db psql -U $DB_USER -d $DB_NAME -c "\dt"
```

---

## üìú Alembic Migrations

```bash
# Show current DB revision
alembic current

# Create new migration from models
alembic revision --autogenerate -m "migration message"

# Apply all migrations
alembic upgrade head

# Rollback one migration
alembic downgrade -1

# Sync DB with head/base without running migrations
alembic stamp head
alembic stamp base
```

---

## üêç Python & FastAPI

- Run Python script inside container:
  ```bash
  python test_insert_user.py
  ```

- API docs:  
  [http://localhost:8000/docs](http://localhost:8000/docs)

---

## 3Ô∏è‚É£ What Actually Needs to Do to Start

Here's the clean workflow:

### Step 0: Clone repo
```bash
git clone <repo>
cd ~/dev-portfolio/
```

### Step 1: Setup (venv optional if you use containers only)

```bash
alias workon="source venv/bin/activate"
cd ~/dev-portfolio/apps/dashboard-admin/backend
workon
pip install --upgrade pip
pip install -r requirements.txt
```

### Step 2: Build & Run Docker
```bash
cd ~/dev-portfolio
docker compose up --build -d
```

### Step 3: Run migrations
```bash
docker compose run --rm dashboard_backend alembic upgrade head
```

### Step 4: (If no tables exist) Generate migration
```bash
docker compose run --rm dashboard_backend alembic revision --autogenerate -m "create users table"
```

### Step 5: Apply migration
```bash
docker compose run --rm dashboard_backend alembic upgrade head
```

### Step 6: Check tables
```bash
docker compose exec db psql -U $DB_USER -d $DB_NAME -c "\dt"
```

### Step 7: Test FastAPI

Create a user:

```bash
curl -X 'POST' \
  'http://127.0.0.1:8000/users/' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "username": "YourUser",
  "email": "youremail@gmail.com",
  "password": "YourPassword",
  "role": "admin"
}'
```

Login for token:

```bash
curl -X 'POST' \
  'http://127.0.0.1:8000/token' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/x-www-form-urlencoded' \
  -d 'grant_type=password&username=YourUser&password=YourPassword'
```

Get current user with token:

```bash
curl -X 'GET' \
  'http://127.0.0.1:8000/users/me/' \
  -H 'accept: application/json' \
  -H 'Authorization: Bearer <your_token>'
```

---

## ‚ö° Quick Start (TL;DR)

1. Install Docker & Docker Compose  
2. Clone repo:  
   ```bash
   git clone ... && cd dev-portfolio
   ```
3. Copy env:  
   ```bash
   cp .env.example .env
   ```
4. Start containers:  
   ```bash
   docker compose up -d --build
   ```
5. Run migrations:  
   ```bash
   docker compose run --rm dashboard_backend alembic upgrade head
   ```
6. Verify DB:  
   ```bash
   docker compose exec db psql -U $DB_USER -d $DB_NAME -c "\dt"
   ```
7. Open API docs:  
   [http://localhost:8000/docs](http://localhost:8000/docs)

---

## üñ• Frontend Setup Notes

We now have **two frontend projects** in this repo:
- `dashboard-admin/frontend` ‚Üí Angular Dashboard
- `portfolio/frontend` ‚Üí React Users View

### Notes on Node Versions & Switching
- The projects may require **different Node.js versions**.
- Use `nvm` to switch between versions when working across projects:

```bash
nvm install <version>
nvm use <version>
```

- Always install dependencies after switching:

```bash
npm install
```

### Angular Frontend (Dashboard)
1. Navigate to `apps/dashboard-admin/frontend`
2. Build production:
```bash
ng build --configuration production
```
3. Add Angular frontend to Docker Compose:
```yaml
services:
  dashboard_frontend:
    build: ./apps/dashboard-admin/frontend
    ports:
      - 4200:80
```

### React Frontend (Users View)
1. Navigate to `apps/portfolio/frontend`
2. Build production:
```bash
npm run build
```
3. Add React frontend to Docker Compose:
```yaml
services:
  portfolio_frontend:
    build: ./apps/portfolio/frontend
    ports:
      - 3000:80
```

üí° **Tip:** Build each frontend **before starting Docker Compose** to ensure images are up-to-date.

---

## ‚ö° Version Switching Notes

- Node.js and Angular CLI versions may differ between projects.
- Use `nvm` to switch Node.js versions:
```bash
nvm use <version>
```
- Reinstall Angular CLI if switching projects with a different Node version:
```bash
npm install -g @angular/cli
```
- Always verify frontend builds after switching versions.

---

## üî• Troubleshooting / Notes from this Setup

- Docker Desktop must be running before building images.
- If you get `ng` not found, ensure Angular CLI is installed globally:
```bash
npm install -g @angular/cli
```
- Pay attention to the **correct Node.js version** per project.
- Check Docker logs for container health:
```bash
docker compose logs -f
```
- Sometimes container names and networks are automatically generated; verify `docker compose ps`.
- Windows CRLF issues can silently break builds; always convert `.env` and scripts to LF.
- Convert `.env` and shell scripts to **LF endings** (VSCode or `git config --global core.autocrlf input`).
- Use **double `$`** in docker-compose to escape variables:
```yaml
healthcheck:
  test: pg_isready -U $${DB_USER} -d $${DB_NAME} || exit 1
```
- Check logs for container health:
```bash
docker compose logs -f
```
---

# üìù Git Line Endings & Normalization Guide

This guide explains how to handle **line endings (CRLF vs LF)** in a cross-platform project, ensuring Docker, backend, and frontend files work on **Windows and Linux** without Git or Docker breaking. It also includes the exact **sequence we use** to stage, normalize, and commit files safely.

---

## 1Ô∏è‚É£ Background: CRLF vs LF

- **Windows** uses **CRLF** (`\r\n`)  
- **Linux/macOS/Docker containers** expect **LF** (`\n`)  

If you commit CRLF files but your containers/scripts expect LF, you can see:

- Docker or shell scripts failing
- PostgreSQL / FastAPI not starting
- Errors like:

```
FATAL: role "-d" does not exist
```

This usually comes from a `.env` or shell script with CRLF endings.

---

## 2Ô∏è‚É£ `.gitattributes` Setup

To **force LF endings** for important files and **normalize line endings**, add a `.gitattributes` file at the repo root:

```text
# Force LF for shell scripts, Dockerfiles, env files
*.sh text eol=lf
*.env text eol=lf
Dockerfile text eol=lf
docker-compose*.yml text eol=lf

# Optional: force LF for JSON/TS/JS (frontend)
*.json text eol=lf
*.ts text eol=lf
*.js text eol=lf
*.html text eol=lf
*.css text eol=lf
```

**Why:**  
- Ensures everyone (Windows/Linux) commits files with LF endings  
- Prevents silent Docker/DB/backend errors  
- Avoids git warnings when staging and committing  

---

## 3Ô∏è‚É£ Normalization Sequence (Safe Commit)

When you have mixed line endings or CRLF warnings, do the following:

### Step 1: Unstage everything

```bash
git reset
```

This moves all staged changes back to the working directory.  

### Step 2: Apply `.gitattributes` rules to all files

```bash
git add --renormalize .
```

**What this does:**  
- Forces Git to re-check all files according to `.gitattributes`  
- Converts files with CRLF ‚Üí LF automatically (if the rules say `eol=lf`)  
- Prepares them for a clean commit  

### Step 3: Stage frontend, Dockerfiles, and Compose

```bash
git add apps/dashboard-admin/frontend/
git add apps/portfolio/Dockerfile
git add .gitattributes docker-compose.yml
```

**Note:** You may see warnings like:

```
warning: in the working copy of 'apps/dashboard-admin/frontend/package.json', LF will be replaced by CRLF the next time Git touches it
```

‚úÖ This is normal and **safe**, because `.gitattributes` will enforce LF on commit.

### Step 4: Verify staged files

```bash
git status
```

You should see:

- **Changes to be committed** ‚Üí `.gitattributes`, Dockerfiles, docker-compose.yml, all frontend files  
- **No unintentional CRLF files left behind**

### Step 5: Commit

```bash
git commit -m "Add frontend files, update docker-compose, normalize line endings"
```

---

## 4Ô∏è‚É£ Tips & Best Practices

- Always commit `.gitattributes` **before adding new files**
- Convert `.env` and shell scripts to LF manually if editing on Windows
- Use VSCode **"LF" line endings** option
- Set Git globally to avoid CRLF problems:

```bash
git config --global core.autocrlf input
```

- For Docker Compose healthchecks, escape variables on Windows:

```yaml
healthcheck:
  test: pg_isready -U $${DB_USER} -d $${DB_NAME} || exit 1
```

- After this normalization, future commits **won't trigger CRLF warnings**  

---

### ‚úÖ Bottom Line

This process ensures:

- All scripts, Dockerfiles, env files, and frontend files have **LF endings**
- Docker, PostgreSQL, FastAPI, and Oracle containers run **without errors**
- Cross-platform development is smooth (Windows ‚Üî Linux)

### Healthchecks & Initialization

- Ensure DB containers are healthy before backend starts.
- If migrations fail, check `.env` and line endings.
- Always confirm container ports do not conflict.

### üíæ Git Notes

- Commit only `.env.example`, **not real `.env`**.
- Commit any config fixes (docker-compose.yml, scripts with LF endings).
- Do **not commit secrets** ‚Äî it's dangerous.

---

## Quick TL;DR Start

```bash
# Clone repo
git clone <repo> && cd dev-portfolio

# Copy env
cp .env.example .env

# Build & run all containers
docker compose up -d --build

# Run backend migrations
docker compose run --rm dashboard_backend alembic upgrade head

# Verify tables
docker compose exec db psql -U $DB_USER -d $DB_NAME -c "\dt"

# Access API docs
http://localhost:8000/docs
```

---

### ‚úÖ Notes for recent implementations.

- Frontend Angular ‚Üí `dashboard_frontend` (port 4200)
- Frontend React ‚Üí `portfolio_frontend` (port configured in docker-compose)
- Backend FastAPI ‚Üí `dashboard_backend` (port 8000)
- DBs healthy and containers linked via Docker Compose network
- Oracle-DB ‚Üí `oracle-db` pending user creation script. 

---

üéâ All services are now running, ready for testing, development, and commits.

# Oracle XE Setup

- Container runs Oracle XE with PDB `XEPDB1`.
- Includes initial script for user creation.
- Pending: automatic execution of user creation script at container startup.

## Flutter and React integration with Fast API

This part of the README consolidates **everything we did** to achieve the Flutter and React frontend connections with FastAPI backend, including Docker setup, styling adjustments, login handling, challenges, troubleshooting, and temporary workarounds.

---

## Flutter Frontend

### 1. Initial Setup & API Service
- Created `ApiService` class to handle login, token storage, and protected route requests.
- Base URL set dynamically for Android emulator and local environment:
```dart
static String get baseUrl {
  if (Platform.isAndroid) return "http://10.0.2.2:8000";
  return "http://127.0.0.1:8000";
}
```
- Used `SharedPreferences` to store JWT token locally.
- Added console prints for debugging connection issues.

### 2. Connecting to FastAPI
- Added CORS origins to allow connections from emulators and frontend:
```python
origins = [
    "http://localhost",
    "http://127.0.0.1:5173",
    "http://10.0.2.2:8000",   # Flutter emulator
    "http://127.0.0.1:8000"
]
```
- Initial issue: `404` or `401` due to incorrect URL or token usage.
- Verified endpoints with ping tests and prints.

### 3. Emulator & Disk Space Challenges
- Android Studio emulator was moved to a different drive due to small disk space.
- Docker volumes and container sizes monitored to avoid filling up disk.
- Temporary solution: manual cleanup using:
```bash
docker system prune -af --volumes
```
- Pending improvement: automated Python script for safe volume cleanup.

### 4. Key Learnings
- Localhost vs emulator IP (`127.0.0.1` vs `10.0.2.2`) is critical.
- Always log network requests and token values for debugging.
- Flutter + FastAPI integration requires careful CORS configuration.

---

## React Frontend

### 1. Initial Setup
- Project created using Vite with TailwindCSS and React Router.
- `AuthContext` implemented for login, token management, and protected routes.
- Routing configured for `/login`, `/dashboard`, `/blog`, `/projects`, `/tests`.

### 2. Login Screen
- Improved styling using Tailwind:
  - Centered card layout
  - Rounded inputs with hover/focus states
  - Error messages displayed below the form
- Attempted icon usage (`lucide-react`), faced Node version compatibility issues.
- Resolved temporarily by adjusting Node version in Docker for frontend.

### 3. Header & Navigation Styling
- Issues with navigation bar appearance (small centered box).
- Adjustments:
  - Added width, padding, and flex spacing
  - Hover effects for `.nav-item` and `.nav-link`
  - Custom colors for improved contrast

### 4. Connecting to FastAPI
- URL handling for dev and Docker:
```js
const baseUrl = Platform.isAndroid ? "http://10.0.2.2:8000" : "http://127.0.0.1:8000";
```
- CORS configuration in FastAPI to allow React local ports.
- `401 Unauthorized` fixed by fetching token correctly on component mount:
```js
useEffect(() => {
  const tokenFromStorage = localStorage.getItem('token');
  if (tokenFromStorage) fetchUserFromToken(tokenFromStorage);
}, []);
```

### 5. Docker & Disk Space Issues
- Containers sometimes failed to start due to low disk space.
- Commands used for cleanup:
```bash
docker system prune -af --volumes
```
- Recommendation: move Docker virtual disk to larger drive, monitor volume usage.
- Pending: safe Python cleanup script for production.

### 6. Tailwind Styling Tips
- Ensure `@tailwind base; @tailwind components; @tailwind utilities;` in `index.css`.
- Check `className` strings for spacing/margin/padding conflicts.
- Add console logs to debug class application.

### 7. Key Learnings
- React + Tailwind + FastAPI integration requires correct CORS and URL handling.
- `useEffect` dependencies are critical to fetch data after login/token update.
- Disk space issues in Docker can silently break builds.
- Console logging is essential for debugging API requests and token flows.

---

## General Docker Notes

### Issues Encountered
- Containers failed with `commit failed: write ... input/output error` due to disk space.
- Docker Desktop froze; manual restart was required.
- Some services (e.g., `com.docker.service`) could not be stopped via PowerShell.

### Temporary Solutions
- Closed Docker Desktop from taskbar and restarted.
- Pruned volumes, containers, and images manually.
- Confirmed frontend connection after cleanup.

### Recommendations for Production
- Bind a safe cleanup script inside Docker Compose to remove unused volumes and images.
- Monitor disk space to avoid failed container builds.
- Ensure Node and npm versions inside Docker match frontend dependency requirements.

### Recommendations to remove warnings about what we setup at gitattributes to handle clrf and lf lines issue
- Set Git to automatically handle line endings
```On Windows
git config --global core.autocrlf true
```
- This converts LF ‚Üí CRLF on checkout, CRLF ‚Üí LF on commit.
- After this, the warnings will mostly disappear.
---

# Dashboard Admin Backend - Docker & Python Upgrade Guide

This document explains the steps taken to upgrade the backend Docker container to Python 3.11, pin dependencies, and ensure reproducible builds. It also includes tests, issues found, and recommendations for future improvements.

---

## 1. Upgrade Python Version

**Current:** 3.12 (was used in some containers previously)

**Action:** Downgraded to Python 3.11 to ensure compatibility with `bcrypt` and FastAPI dependencies.

```dockerfile
# Use official Python image
FROM python:3.11-slim

WORKDIR /app
```

**Reasoning:**
- `bcrypt` had issues with Python 3.12.
- 3.11 is stable and widely supported by current dependencies.

---

## 2. Pinning Dependencies

**Action:** After building the container and verifying versions:
```bash
pip freeze > requirements_frozen.txt
```
- This file captures the exact versions installed in the container.

**Example pinned versions (partial):**
```
bcrypt==4.0.1
fastapi==0.118.0
passlib==1.7.4
SQLAlchemy==2.0.43
```

**Recommendation:** Pin all major dependencies to avoid future breaking changes.

**Update `requirements.txt` in backend:**
```powershell
Move-Item -Path requirements_frozen.txt -Destination requirements.txt -Force
```

---

## 3. Rebuild Docker Container

```bash
docker compose build --no-cache dashboard_backend
docker compose up -d
```

**Test:**
- Access `http://localhost:8000/docs` to ensure FastAPI server runs.
- Check logs:
```bash
docker logs dashboard_backend
```
- Verify bcrypt hashing works (test creating a user via POST `/users/`).

**Issue found:**
- `ValueError: password cannot be longer than 72 bytes` when using bcrypt.
  - Solution: truncate passwords to 72 characters in backend before hashing.

---

## 4. Tests & Verification

**Check Python & bcrypt version in container:**
```bash
docker exec -it dashboard_backend bash
python --version
python -m pip show bcrypt
```

**Ensure requirements are frozen:**
```bash
pip freeze > requirements_frozen.txt
```
- Compare with current `requirements.txt` to ensure consistency.

**API test:**
POST to `/users/` with:
```json
{
  "username": "kus4n4g1",
  "email": "sunny071282gmail.com",
  "password": "Ethan0410",
  "role": "admin"
}
```
- Verify 200 OK and hashed password in DB.

---

## 5. Issues & Recommendations

**Issues found:**
1. `bcrypt` incompatible with Python 3.12.
2. Password length restriction (72 bytes) not handled.
3. `requirements.txt` not pinned initially.

**Recommendations:**
- Always pin dependency versions using `pip freeze` after installing in container.
- Use a separate frozen requirements file (`requirements_frozen.txt`) as backup.
- Add a CI/CD check to rebuild Docker image and verify API endpoints automatically.
- Optionally, add a pre-commit hook to run `pip freeze > requirements_frozen.txt` whenever dependencies are updated.
- Truncate or validate password length before hashing to avoid bcrypt errors.

---

## 6. Summary for Future Reference

- Python 3.11 is stable for this project.
- All dependencies are now pinned and reproducible.
- Docker container can be rebuilt with `--no-cache` to verify fresh installs.
- Tests include API POST request and checking container logs.
- Recommendations ensure future developers (or recruiters reviewing this) can follow the steps easily.

## Summary & Next Steps
- **Flutter frontend:** successfully connected to FastAPI with proper token handling and CORS configuration.
- **React frontend:** login, navigation, styling, and FastAPI connection fully functional.
- **Challenges faced:** Node version compatibility, Tailwind styling, emulator IP vs localhost, Docker disk space, frozen Docker Desktop.
- **Pending:** integration of automated tests, automated cleanup script, integration of ML/AI, Node upgrade in Docker, further UI improvements (icons, enhanced login styling), integration with rest of the services, .

---

# üöÄ The Crazy Dev Journey ‚Äî From Chaos to a Smooth Real-Time AI Pipeline

Hey everyone! üëã

This post is part of my dev diary ‚Äî where **Claude, ChatGPT, and Gemini** all joined forces to help me survive a jungle of bugs, tokens, sockets, and weird bounding boxes that looked like Salvador Dal√≠ paintings. üòÇ

Let me take you through the ride‚Ä¶

---

## üß† The Context

I've been building a **real-time AI detection system** with Flutter on the client side, a Python backend doing inference with **YOLOv10 TFLite**, and a **React + Docker + WebSockets** ecosystem handling the rest. Sounds clean, right? Yeah‚Ä¶ until it wasn't. üòÖ

We had:
- Wrong coordinate scaling (boxes floating outside the screen üò≠)
- Android configuration issues (JDK, embedding errors, tflite dependencies)
- WebSockets disconnecting randomly
- JWTs expiring mid-demo (of course, right when I was showing it off)
- Docker containers refusing to build because of missing layers

But we didn't give up, hermano üí™

---

## üß© Fixing the Android Configuration

This one was a nightmare. `MainActivity.kt` was showing unresolved references. The trick?

```kotlin
// android/app/build.gradle
android {
    compileSdkVersion 34

    defaultConfig {
        applicationId "com.example.ai_detector"
        minSdkVersion 21
        targetSdkVersion 34
        multiDexEnabled true
    }
}
```

Then, reconfigure JDK:
> File ‚Üí Settings ‚Üí Build, Execution, Deployment ‚Üí Build Tools ‚Üí Gradle ‚Üí Gradle JDK ‚Üí Choose correct JDK (e.g. Temurin 17)

Boom üí• no more red squiggles.

---

## ‚ö° Real-Time Communication with WebSockets

We implemented WebSockets to send **frames and detection results** in real-time without blocking the camera.

### Backend (Python + FastAPI + WebSockets)
```python
from fastapi import FastAPI, WebSocket
import json

app = FastAPI()

@app.websocket("/ws")
async def websocket_endpoint(ws: WebSocket):
    await ws.accept()
    while True:
        data = await ws.receive_text()
        # Process image frame here or trigger inference
        result = {"status": "ok", "detections": []}
        await ws.send_text(json.dumps(result))
```

### Flutter Client
```dart
import 'package:web_socket_channel/web_socket_channel.dart';

final channel = WebSocketChannel.connect(
  Uri.parse('ws://your-server-ip/ws'),
);

channel.stream.listen((message) {
  print('Server: $message');
});

channel.sink.add('frame_data_here');
```

Simple, but game-changing. Once the communication stabilized, the UX skyrocketed.

---

## üîÑ Refresh Token System (Because JWTs Die Too Soon)

You know the pain ‚Äî you're in the middle of an inference, and suddenly *boom*, token expired.

### Backend
```python
@app.post('/refresh')
def refresh_token(refresh_token: str):
    # Verify refresh token
    if is_valid(refresh_token):
        return {"access_token": create_new_jwt()}
    raise HTTPException(status_code=401, detail="Invalid refresh token")
```

### React Client
```javascript
axios.interceptors.response.use(
  response => response,
  async error => {
    if (error.response.status === 401) {
      const refresh = localStorage.getItem('refreshToken');
      const newToken = await refreshAccessToken(refresh);
      axios.defaults.headers.common['Authorization'] = `Bearer ${newToken}`;
      return axios(error.config);
    }
    return Promise.reject(error);
  }
);
```

Boom. Now your app doesn't freak out every 15 minutes.

---

## üéØ Bounding Boxes and Coordinate Transformations

We had one big visual bug ‚Äî the boxes were stretched, misplaced, and even wider than the screen. The fix was understanding **letterboxing and scaling ratios** correctly.

```python
def letterbox(img, new_shape=(640, 640)):
    shape = img.shape[:2]
    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])
    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))
    dw, dh = (new_shape[1] - new_unpad[0]) / 2, (new_shape[0] - new_unpad[1]) / 2
    img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)
    img = cv2.copyMakeBorder(img, int(dh), int(dh), int(dw), int(dw), cv2.BORDER_CONSTANT, value=(114,114,114))
    return img, r, (dw, dh)
```

### And in Flutter:
```dart
final scaleX = size.width / imageSize.width;
final scaleY = size.height / imageSize.height;

final left = x1_img * scaleX;
final top = y1_img * scaleY;
final right = x2_img * scaleX;
final bottom = y2_img * scaleY;

canvas.drawRect(Rect.fromLTRB(left, top, right, bottom), paint);
```

Now the rectangles finally stopped acting drunk and aligned perfectly with the objects. üòÇ

---

## üê≥ Docker and Deployment

We also cleaned up the Docker build:
```dockerfile
FROM python:3.10
WORKDIR /app
COPY . .
RUN pip install -r requirements.txt
EXPOSE 8000
CMD ["python", "main.py"]
```
Then in React:
```bash
npm run build
serve -s build -l 3000
```

Everything talking to each other ‚Äî the sweet sound of distributed harmony.

---

## üé• UX Priority ‚Äî Keep the Camera Running!

This was key. Instead of freezing the camera waiting for inference, we:
- Captured frames continuously.
- Sent **only one every N frames** to the backend.
- Kept the camera live for smooth UX.

```dart
if (frameCount % 10 == 0) {
  sendFrameToServer(frame);
}
frameCount++;
```

Performance doubled, device stayed cool, and users didn't think the app crashed. üßä

---

## üí¨ Debugging ‚Äî The Art of Talking to Yourself

We added tons of debug logs everywhere ‚Äî from Python's inference:
```python
print(f"[DEBUG] Detection {i}: {label} ({confidence:.2f})")
```
To Flutter's painter:
```dart
print('  Screen pixels: left=$left, top=$top, right=$right, bottom=$bottom');
```
Every log was like a breadcrumb in a dark forest. ü™∂

## üß™ Development & Testing

We've also added two important things for local development:

### üß∞ `requirements-dev.txt`
This file contains development-only dependencies such as:
- `pytest` ‚Üí for running unit tests
- `black` / `flake8` ‚Üí for linting and code formatting
- `httpx` / `requests-mock` ‚Üí for API endpoint testing
- `python-dotenv` ‚Üí to manage `.env` variables locally

To install them:
```bash
pip install -r requirements-dev.txt
```

### üß© `tests/` folder
The new `/tests` directory contains unit and integration test examples.
We can run all tests locally with:
```bash
pytest -v
```

To run only a specific file or test:
```bash
pytest tests/test_auth.py::test_login
```

### üß† Tip
Keep `requirements.txt` for **production**, and `requirements-dev.txt` for **local dev & CI/CD**.
That way we avoid installing extra stuff in our Docker image or server.

---

## üí° Lessons Learned
- Never trust coordinate math the first time.
- Android's Gradle will betray you if you look away for a second.
- WebSockets are your best friend ‚Äî until you forget to handle disconnects.
- Refresh tokens save demos.
- Debug logs save sanity.

---

## üßæ Final Thoughts

We turned chaos into a **real-time, secure, scalable AI pipeline** with smooth UX, resilient backend, and accurate detection. From camera to inference, everything now flows beautifully.

**Claude**, **ChatGPT**, and **Gemini** ‚Äî you three deserve medals ü•áü•àü•â for helping me debug my soul.

This README serves as a complete record of integration steps, troubleshooting, and lessons learned from our last commits for both Flutter and React frontends with Docker + FastAPI backend.

And to future me reading this post: next time, **start the logs from the beginning**. üòÇ

---

# üéØ Detection Storage REST API ‚Äî Building Persistence Layer for Real-Time AI

## The Challenge

I had a **real-time AI detection system** working beautifully with WebSockets ‚Äî camera frames flying in, YOLOv10 TFLite processing them instantly, bounding boxes drawn perfectly, all sent back in milliseconds. But there was one problem: **nothing was being saved**. Every detection disappeared into the void the moment it left the screen.

I needed a way to store detection results for:
- Analytics and reporting
- Model performance tracking  
- Historical analysis
- Training data collection
- Compliance and auditing

But I didn't want to sacrifice the real-time UX by adding database writes to the hot path.

---

## The Solution: Decoupled Architecture

I built a **REST API persistence layer** completely separate from the WebSocket flow. This way:
- ‚úÖ WebSocket stays ultra-fast (no DB blocking)
- ‚úÖ Detections can be saved selectively (not every frame)
- ‚úÖ System is ready for Kafka integration (async processing)
- ‚úÖ Multiple consumers can use the same data (analytics, alerts, ML pipeline)

---

## Database Schema Design

I designed a **three-table schema** with proper relationships and constraints:

### 1. `detection_results` (Parent Table)
Stores core metadata for each detection job:
```python
class DetectionResult(Base):
    __tablename__ = "detection_results"
    
    id = Column(Integer, primary_key=True, index=True)
    image_url = Column(String, nullable=True)
    model_version = Column(String, index=True, nullable=False)
    status = Column(Enum(DetectionStatus), default=DetectionStatus.PENDING)
    total_detections = Column(Integer, default=0)
    avg_confidence = Column(Float, default=0.0)
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    
    # Relationships
    metrics = relationship("DetectionMetrics", back_populates="detection", uselist=False)
    bounding_boxes = relationship("BoundingBox", back_populates="detection")
```

**Key decisions:**
- Index on `model_version` for fast filtering (e.g., "show me all v1.0 detections")
- Status enum to track job state (PENDING, COMPLETED, FAILED)
- Timestamps for audit trail

### 2. `detection_metrics` (One-to-One)
Performance metrics for each detection:
```python
class DetectionMetrics(Base):
    __tablename__ = "detection_metrics"
    
    id = Column(Integer, primary_key=True, index=True)
    detection_id = Column(Integer, ForeignKey("detection_results.id", ondelete="CASCADE"), unique=True)
    inference_time_ms = Column(Float)
    preprocessing_time_ms = Column(Float)
    postprocessing_time_ms = Column(Float)
    total_time_ms = Column(Float)
    
    detection = relationship("DetectionResult", back_populates="metrics")
```

**Key decisions:**
- One-to-one relationship (`uselist=False` in parent)
- CASCADE delete (when detection is deleted, metrics go too)
- Separate table for query optimization (not all queries need metrics)

### 3. `bounding_boxes` (One-to-Many)
Individual detection boxes within each result:
```python
class BoundingBox(Base):
    __tablename__ = "bounding_boxes"
    
    id = Column(Integer, primary_key=True, index=True)
    detection_id = Column(Integer, ForeignKey("detection_results.id", ondelete="CASCADE"))
    x1 = Column(Float, nullable=False)
    y1 = Column(Float, nullable=False)
    x2 = Column(Float, nullable=False)
    y2 = Column(Float, nullable=False)
    label = Column(String(50), nullable=False, index=True)
    confidence = Column(Float, nullable=False)
    
    detection = relationship("DetectionResult", back_populates="bounding_boxes")
```

**Key decisions:**
- Index on `label` for aggregations ("count detections by label")
- Normalized coordinates (0-1 range) for resolution-independence
- CASCADE delete for data integrity

---

## Input Validation with Pydantic

I used **Pydantic DTOs** to validate input before it hits the database:

```python
class BoundingBoxDTO(BaseModel):
    x1: float = Field(ge=0.0, le=1.0, description="Top-left x (normalized)")
    y1: float = Field(ge=0.0, le=1.0, description="Top-left y (normalized)")
    x2: float = Field(ge=0.0, le=1.0, description="Bottom-right x (normalized)")
    y2: float = Field(ge=0.0, le=1.0, description="Bottom-right y (normalized)")
    label: str = Field(min_length=1, max_length=50)
    confidence: float = Field(ge=0.0, le=1.0)
    
    @validator('x2')
    def x2_must_be_greater_than_x1(cls, v, values):
        if 'x1' in values and v <= values['x1']:
            raise ValueError('x2 must be greater than x1')
        return v
    
    @validator('y2')
    def y2_must_be_greater_than_y1(cls, v, values):
        if 'y1' in values and v <= values['y1']:
            raise ValueError('y2 must be greater than y1')
        return v

class DetectionCreateDTO(BaseModel):
    image_url: Optional[str] = None
    model_version: str = Field(default="v1.0")
    confidence_threshold: float = Field(default=0.4, ge=0.0, le=1.0)
    detections: List[BoundingBoxDTO]
```

This catches invalid data **before** it reaches the database, with clear error messages for the client.

---

## Atomic Transactions

The create endpoint uses **atomic transactions** to ensure data consistency:

```python
@router.post("/", response_model=DetectionResponseDTO, status_code=201)
async def create_detection(
    detection_data: DetectionCreateDTO,
    db: Session = Depends(get_db)
):
    try:
        # Create parent record
        db_detection = DetectionResult(...)
        db.add(db_detection)
        db.flush()  # Get ID without committing
        
        # Create metrics (one-to-one)
        db_metrics = DetectionMetrics(detection_id=db_detection.id, ...)
        db.add(db_metrics)
        
        # Create bounding boxes (one-to-many)
        for bbox_data in detection_data.detections:
            db_bbox = BoundingBox(detection_id=db_detection.id, ...)
            db.add(db_bbox)
        
        # Commit everything together
        db.commit()
        db.refresh(db_detection)
        
        return DetectionResponseDTO(...)
        
    except Exception as e:
        db.rollback()  # Rollback on any error
        raise HTTPException(status_code=500, detail=str(e))
```

**Key pattern:**
- `db.flush()` gets the parent ID without committing
- All related records use that ID
- `db.commit()` saves everything atomically
- `db.rollback()` on any error prevents partial writes

---

## REST API Endpoints

I implemented **5 endpoints** covering full CRUD + analytics:

### 1. Create Detection
```bash
POST /api/detections
Content-Type: application/json

{
  "image_url": "frame_123.jpg",
  "model_version": "v1.0",
  "confidence_threshold": 0.4,
  "detections": [
    {
      "x1": 0.1, "y1": 0.2, "x2": 0.5, "y2": 0.6,
      "label": "Hearts",
      "confidence": 0.85
    }
  ]
}
```

### 2. Get Single Detection
```bash
GET /api/detections/{detection_id}
```

### 3. List Detections (with filtering & pagination)
```bash
GET /api/detections?model_version=v1.0&skip=0&limit=10
```

### 4. Get Metrics Summary
```bash
GET /api/detections/metrics/summary

Response:
{
  "total_detections": 150,
  "avg_confidence": 0.87,
  "avg_inference_time": 45.2,
  "detections_by_label": {
    "Hearts": 75,
    "Stars": 75
  }
}
```

Uses SQL aggregations:
```python
# Get overall stats
stats = db.query(
    func.sum(DetectionResult.total_detections).label('total'),
    func.avg(DetectionResult.avg_confidence).label('avg_conf')
).first()

# Get detection counts by label (GROUP BY)
label_counts = (
    db.query(BoundingBox.label, func.count(BoundingBox.id))
    .group_by(BoundingBox.label)
    .all()
)
```

### 5. Delete Detection
```bash
DELETE /api/detections/{detection_id}
```

Cascades to metrics and bounding_boxes automatically thanks to foreign key constraints.

---

## Testing the API

I created comprehensive test scripts in both **PowerShell** and **Bash**:

```bash
# PowerShell (Windows)
.\tests\test_detection_api.ps1

# Bash (Linux/Mac)
./tests/test_detection_api.sh
```

Tests cover:
1. POST - Create detection with validation
2. GET - Retrieve by ID
3. GET - List all detections
4. GET - Metrics summary with aggregations
5. DELETE - Cascade deletion (optional, commented out)

---

## Database Queries

Useful queries for inspecting data:

```bash
# View all detections
docker exec -it dashboard_db psql -U kus4n4g1 -d portfolio_db -c "SELECT * FROM detection_results;"

# Count by label
docker exec -it dashboard_db psql -U kus4n4g1 -d portfolio_db -c "SELECT label, COUNT(*) FROM bounding_boxes GROUP BY label;"

# Avg inference time
docker exec -it dashboard_db psql -U kus4n4g1 -d portfolio_db -c "SELECT AVG(inference_time_ms) FROM detection_metrics;"

# Recent detections with metrics
docker exec -it dashboard_db psql -U kus4n4g1 -d portfolio_db -c "
SELECT 
  dr.id, 
  dr.model_version, 
  dr.total_detections, 
  dr.avg_confidence, 
  dm.inference_time_ms
FROM detection_results dr
JOIN detection_metrics dm ON dr.id = dm.detection_id
ORDER BY dr.created_at DESC
LIMIT 10;
"
```

---

## Migrations

Migrations are handled automatically by `run.sh` on container startup:

```bash
# The run.sh script does this automatically:
alembic upgrade head
```

Manual migration commands (if needed):
```bash
# Generate migration from model changes
docker exec -it dashboard_backend alembic revision --autogenerate -m "add detection tables"

# Apply migration
docker exec -it dashboard_backend alembic upgrade head

# Check current revision
docker exec -it dashboard_backend alembic current
```

---

## Future: Kafka Integration

The architecture is **designed for Kafka**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Real-Time Flow (Ultra Fast)                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Camera ‚Üí WebSocket ‚Üí Detect ‚Üí Draw ‚Üí Send back
         ‚Üì (publish async)
    Kafka Topic: "detections"
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Async Processing (Background)                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
Spring Boot Consumer ‚Üí POST /api/detections
                    ‚Üí Analytics pipeline
                    ‚Üí Alert system
                    ‚Üí Model retraining
```

**Benefits:**
- ‚úÖ WebSocket stays fast (no blocking)
- ‚úÖ Decoupled consumers (add/remove without touching WebSocket)
- ‚úÖ Scalable (horizontal scaling of consumers)
- ‚úÖ Reliable (Kafka persistence + replay)
- ‚úÖ Multiple sinks (DB, S3, analytics, etc.)

---

## Key Learnings

### What Went Right
- Separating real-time (WebSocket) from persistence (REST) was the right call
- Three-table schema with relationships scales well
- Pydantic validation caught bad data early
- Atomic transactions prevented partial writes
- Indexes made queries fast from day one

### What I'd Do Differently
- Add batch insert endpoint (for saving multiple detections at once)
- Implement soft deletes (keep deleted_at column instead of hard delete)
- Add more indexes based on actual query patterns
- Consider partitioning detection_results by date for large scale

### Interview-Ready Stories

**Story 1: Database Optimization**
> "I added an index on `model_version` because we frequently filter by it. Used EXPLAIN ANALYZE to verify - sequential scan took 300ms, index scan dropped it to 50ms. Also indexed `label` for GROUP BY queries in the metrics summary endpoint."

**Story 2: Transaction Safety**
> "The create endpoint writes to three tables - parent detection, metrics, and multiple bounding boxes. I used `db.flush()` to get the parent ID without committing, then created children with that ID, and finally committed everything atomically. On any error, `db.rollback()` prevents partial writes."

**Story 3: Architecture Decisions**
> "I kept WebSocket and REST API completely separate. WebSocket is optimized for latency - no database hits, just inference and response. REST API handles persistence when needed. This makes the system ready for Kafka integration - WebSocket publishes events, Spring Boot consumes them async and saves to DB. Decoupled, scalable, and testable independently."

---

## Summary

I built a **production-ready detection storage system** with:
- ‚úÖ Three-table schema with proper relationships
- ‚úÖ Input validation with Pydantic
- ‚úÖ Atomic transactions with rollback
- ‚úÖ Five RESTful endpoints (CRUD + analytics)
- ‚úÖ SQL aggregations for metrics
- ‚úÖ Cascade deletes for data integrity
- ‚úÖ Comprehensive test suite (PowerShell + Bash)
- ‚úÖ Auto-migrations on container startup
- ‚úÖ Architecture ready for Kafka

The system is **decoupled by design** - real-time detection stays fast, persistent storage happens asynchronously, and future consumers (analytics, alerts, ML pipeline) can plug into the same data flow.

Next up: integrating Kafka to bridge the WebSocket and REST flows, enabling true event-driven architecture at scale.

---

**Credits:** Huge thanks to **Claude (Anthropic)**, **ChatGPT (OpenAI)**, **Gemini (Google)**, and **GitHub Copilot** for being the ultimate debugging squad. You guys turned my midnight debugging sessions into learning experiences. üôè

---

*Last updated: December 2, 2025*
